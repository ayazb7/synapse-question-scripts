SynapseUK Question Generation & Upload Guide (Batch)

This guide shows how to:
1) Run the batch generator for multiple topics
2) Produce per-topic CSVs matching the Supabase `questions` table
3) Upload the CSV(s) into Supabase using the website (Studio)

Assumption
- You are running commands from the `question_scripts/` directory

Prerequisites
- Python 3.10+ installed
- Install dependencies:
  pip install openai python-dotenv tqdm
- Set your OpenAI API key in the shell before running:
  export OPENAI_API_KEY=sk-...

Run the batch generator
- Script: batch_generate.py (calls the other scripts internally)
- Output: one CSV per topic in `out/` and a `done_topics.txt` log

Example (recommended defaults):
  python batch_generate.py \
    --out-dir out \
    --n 30 \
    --model gpt-5 \
    --batch-size 10 \
    --temperature 1

Notes
- You can add `--seed 0` for deterministic option shuffling.
- Excluded topics are listed inside the script (EXCLUDED_TOPIC_NAMES).
- Generated CSVs will appear like: `out/acid-base-abnormality.csv`.

Upload the CSV into Supabase (Studio website)
1) Open Supabase Studio → Table Editor → select the `questions` table
2) Click "Insert data" → "Import data" → Upload the CSV from `question_scripts/out/`
3) Confirm the column mapping matches exactly:
   topic_id, type, stem, is_active, explanation_eli5, explanation_l1_points,
   explanation_points_by_option, explanation_l2, options, correct_answer,
   created_at, updated_at
4) Column types to check:
   - options, explanation_l1_points, explanation_points_by_option → JSON/JSONB
   - correct_answer → integer (0–4)
   - created_at, updated_at → timestamptz (ISO 8601 with Z is fine)
5) Import and verify by filtering rows for the intended `topic_id`

Example topic confirmation
- Example file: question_scripts/out/acid-base-abnormality.csv
- After import, filter the `questions` table by that topic’s UUID to confirm rows.

Troubleshooting
- JSON parse errors: ensure you import the CSV generated by this batch (do not hand-edit JSON fields in the CSV).
- Wrong topic: regenerate with corrected `topic_id` upstream and re-import, or delete the incorrect rows in Studio and re-import.
- Duplicates: if you import the same CSV twice, delete by `topic_id` and re-import once.
